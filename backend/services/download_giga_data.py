"""
GIGA School Data Downloader
æ–‡éƒ¨ç§‘å­¦çœã€Œå­¦æ ¡ã«ãŠã‘ã‚‹æ•™è‚²ã®æƒ…å ±åŒ–ã®å®Ÿæ…‹ç­‰ã«é–¢ã™ã‚‹èª¿æŸ»ï¼ˆä»¤å’Œ5å¹´åº¦ï¼‰ã€ãƒ‡ãƒ¼ã‚¿ã‚’åŽé›†

Data Source: e-Stat
https://www.e-stat.go.jp/stat-search/files?statInfId=000040221910&fileKind=0
"""

import httpx
import pandas as pd
import os
import psycopg2
from psycopg2.extras import RealDictCursor
import io
import time

import zipfile
import io

class GigaDataDownloader:
    # e-Stat ä»¤å’Œ5å¹´åº¦æ•™è‚²æƒ…å ±åŒ–èª¿æŸ» 47éƒ½é“åºœçœŒåˆ¥Excel URLãƒªã‚¹ãƒˆ
    PREFECTURE_URLS = [
        {"title": "01 åŒ—æµ·é“", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221906&fileKind=0"},
        {"title": "02 é’æ£®çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221907&fileKind=0"},
        {"title": "03 å²©æ‰‹çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221908&fileKind=0"},
        {"title": "04 å®®åŸŽçœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221909&fileKind=0"},
        {"title": "05 ç§‹ç”°çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221910&fileKind=0"},
        {"title": "06 å±±å½¢çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221911&fileKind=0"},
        {"title": "07 ç¦å³¶çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221912&fileKind=0"},
        {"title": "08 èŒ¨åŸŽçœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221913&fileKind=0"},
        {"title": "09 æ ƒæœ¨çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221914&fileKind=0"},
        {"title": "10 ç¾¤é¦¬çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221915&fileKind=0"},
        {"title": "11 åŸ¼çŽ‰çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221916&fileKind=0"},
        {"title": "12 åƒè‘‰çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221917&fileKind=0"},
        {"title": "13 æ±äº¬éƒ½", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221918&fileKind=0"},
        {"title": "14 ç¥žå¥ˆå·çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221919&fileKind=0"},
        {"title": "15 æ–°æ½ŸçœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221920&fileKind=0"},
        {"title": "16 å¯Œå±±çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221921&fileKind=0"},
        {"title": "17 çŸ³å·çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221922&fileKind=0"},
        {"title": "18 ç¦äº•çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221923&fileKind=0"},
        {"title": "19 å±±æ¢¨çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221924&fileKind=0"},
        {"title": "20 é•·é‡ŽçœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221925&fileKind=0"},
        {"title": "21 å²é˜œçœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221926&fileKind=0"},
        {"title": "22 é™å²¡çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221927&fileKind=0"},
        {"title": "23 æ„›çŸ¥çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221928&fileKind=0"},
        {"title": "24 ä¸‰é‡çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221929&fileKind=0"},
        {"title": "25 æ»‹è³€çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221930&fileKind=0"},
        {"title": "26 äº¬éƒ½åºœ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221931&fileKind=0"},
        {"title": "27 å¤§é˜ªåºœ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221932&fileKind=0"},
        {"title": "28 å…µåº«çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221933&fileKind=0"},
        {"title": "29 å¥ˆè‰¯çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221934&fileKind=0"},
        {"title": "30 å’Œæ­Œå±±çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221935&fileKind=0"},
        {"title": "31 é³¥å–çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221936&fileKind=0"},
        {"title": "32 å³¶æ ¹çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221937&fileKind=0"},
        {"title": "33 å²¡å±±çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221938&fileKind=0"},
        {"title": "34 åºƒå³¶çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221939&fileKind=0"},
        {"title": "35 å±±å£çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221940&fileKind=0"},
        {"title": "36 å¾³å³¶çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221941&fileKind=0"},
        {"title": "37 é¦™å·çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221942&fileKind=0"},
        {"title": "38 æ„›åª›çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221943&fileKind=0"},
        {"title": "39 é«˜çŸ¥çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221944&fileKind=0"},
        {"title": "40 ç¦å²¡çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221945&fileKind=0"},
        {"title": "41 ä½è³€çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221946&fileKind=0"},
        {"title": "42 é•·å´ŽçœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221947&fileKind=0"},
        {"title": "43 ç†Šæœ¬çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221948&fileKind=0"},
        {"title": "44 å¤§åˆ†çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221949&fileKind=0"},
        {"title": "45 å®®å´ŽçœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221950&fileKind=0"},
        {"title": "46 é¹¿å…å³¶çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221951&fileKind=0"},
        {"title": "47 æ²–ç¸„çœŒ", "url": "https://www.e-stat.go.jp/stat-search/file-download?statInfId=000040221952&fileKind=0"}
    ]

    def __init__(self):
        self.client = httpx.Client(timeout=30.0, follow_redirects=True)
        self.conn = psycopg2.connect(
            host=os.getenv("POSTGRES_HOST", "localhost"),
            port=int(os.getenv("POSTGRES_PORT", "5432")),
            user=os.getenv("POSTGRES_USER", "zoom_admin"),
            password=os.getenv("POSTGRES_PASSWORD", "password"),
            dbname=os.getenv("POSTGRES_DB", "zoom_dx_db")
        )
        self.cur = self.conn.cursor(cursor_factory=RealDictCursor)

    def download_and_import_all(self):
        """å…¨47éƒ½é“åºœçœŒã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†"""
        total = len(self.PREFECTURE_URLS)
        print(f"ðŸš€ Starting Import for {total} prefectures...")
        
        success_total = 0
        error_total = 0
        
        for i, item in enumerate(self.PREFECTURE_URLS):
            title = item['title']
            url = item['url']
            print(f"\n[{i+1}/{total}] Processing {title}...")
            
            try:
                time.sleep(1) # E-Statã¸ã®è² è·è»½æ¸›
                response = self.client.get(url)
                response.raise_for_status()
                
                # Header=Noneã§èª­ã¿è¾¼ã‚€
                df = pd.read_excel(io.BytesIO(response.content), sheet_name=0, header=None)
                
                # ãƒ‡ãƒãƒƒã‚°æ¤œæŸ» (æœ€åˆã®1ä»¶ã®ã¿)
                # if i == 0:
                #    self.inspect_data(df)

                # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ
                count = self.import_data(df)
                success_total += count
                
            except Exception as e:
                print(f"âŒ Failed to process {title}: {e}")
                error_total += 1
                # traceback.print_exc()
        
        print(f"\nðŸŽ‰ All Done! Total Success Records: {success_total}, Errors (Prefectures): {error_total}")

    def import_data(self, df):
        """ãƒ‡ãƒ¼ã‚¿ã‚’è§£æžã—ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (Returns: processed count)"""
        # ãƒžãƒƒãƒ”ãƒ³ã‚°ç”¨è¾žæ›¸ (ã“ã‚Œã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ã‚‚è‰¯ã„ãŒã€ä»¶æ•°å°‘ãªã„ã®ã§éƒ½åº¦å‘¼ã¶ã‹ã€__init__ã§å‘¼ã¶ã‹)
        # æ¯Žå›žå‘¼ã¶ã¨DBè² è·ã«ãªã‚‹ã®ã§ã€__init__ã§ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã«ã—ã¦ãŠãã®ãŒãƒ™ã‚¿ãƒ¼ã ãŒã€
        # ã“ã“ã§ã¯ç°¡æ˜“ã«self.curã‚’ä½¿ã†
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼æ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯ (æ—¢å­˜)
        # ... (ä¸­ç•¥) ...
        # return success_count ã‚’è¿½åŠ ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
        return self._process_dataframe(df)

    def _process_dataframe(self, df):
        # æ—¢å­˜ã®import_dataã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ã“ã“ã«ç§»å‹•
        # æˆ»ã‚Šå€¤ã¨ã—ã¦ success_count ã‚’è¿”ã™
        
        # ãƒžãƒƒãƒ”ãƒ³ã‚°ç”¨è¾žæ›¸ä½œæˆ
        city_map = self.get_city_code_map() # æ¯Žå›žã“ã‚Œå‘¼ã¶ã®ã¯ç„¡é§„ã ãŒã€ä¸€æ—¦ãã®ã¾ã¾
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’æ¤œç´¢
        header_row_idx = -1
        # ä»¤å’Œ5å¹´åº¦èª¿æŸ»ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        target_keywords = ['å¸‚åŒºç”ºæ‘åˆ¥', 'å­¦ç¿’è€…ç”¨PCç·å°æ•°', 'å…ç«¥ç”Ÿå¾’æ•°']
        
        for i in range(20):
            row_vals = [str(x) for x in df.iloc[i].tolist()]
            row_str = "".join(row_vals)
            if all(k in row_str for k in target_keywords):
                header_row_idx = i
                break
        
        if header_row_idx == -1:
            print("âŒ Header row not found in this file.")
            return 0

        header_row = df.iloc[header_row_idx]
        col_indices = {}
        
        target_cols_map = {
            'å¸‚åŒºç”ºæ‘åˆ¥': 'municipality',
            'å…ç«¥ç”Ÿå¾’æ•°': 'students',
            'å­¦ç¿’è€…ç”¨PCç·å°æ•°': 'learner_pcs',
            'å…ç«¥ç”Ÿå¾’ä¸€äººå½“ãŸã‚Šã®å­¦ç¿’è€…ç”¨PCå°æ•°': 'pc_per_student',
        }
        
        for i in range(len(header_row)):
            val = header_row[i]
            if pd.notna(val):
                s = str(val).replace('\n', '').replace(' ', '').replace('ã€€', '')
                for t_key, t_orig in target_cols_map.items():
                    if t_key in s:
                        col_indices[t_orig] = i
        
        # éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘åˆ—
        pref_col_idx = -1
        city_col_idx = -1
        
        for i in range(header_row_idx):
            row_vals = [str(x) for x in df.iloc[i].tolist()]
            for j, val in enumerate(row_vals):
                if 'éƒ½é“åºœçœŒå' in val:
                    pref_col_idx = j
                if 'å¸‚åŒºç”ºæ‘å' in val:
                    city_col_idx = j
        
        if pref_col_idx == -1: pref_col_idx = 1
        # Municipality col index might be determined by 'municipality' key if found
        if 'municipality' in col_indices:
            city_col_idx = col_indices['municipality']
        
        if city_col_idx == -1: city_col_idx = 2

        success_count = 0
        start_row = header_row_idx + 1
        
        current_pref = None
        # éƒ½é“åºœçœŒåã®ã‚»ãƒƒãƒˆ (åˆ¤å®šç”¨)
        all_prefs = set(k[0] for k in city_map.keys())

        for i in range(start_row, len(df)):
            row = df.iloc[i]
            # å¸‚åŒºç”ºæ‘åˆ—(ã¾ãŸã¯åå‰åˆ—)ã®å€¤
            name_val = row[city_col_idx]
            if pd.isna(name_val):
                continue
            
            name = str(name_val).replace(' ', '').replace('ã€€', '')
            if name == 'nan' or 'å¹³å‡' in name or 'åˆè¨ˆ' in name:
                continue
            
            # éƒ½é“åºœçœŒåã‹ã©ã†ã‹åˆ¤å®š
            if name in all_prefs:
                current_pref = name
                continue # éƒ½é“åºœçœŒè¡Œã¯ã‚¹ã‚­ãƒƒãƒ—
            
            # ç¾åœ¨ã®éƒ½é“åºœçœŒãŒæœªè¨­å®šã§ã€ã‹ã¤åå‰ãŒéƒ½é“åºœçœŒã£ã½ã„å ´åˆ(ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)
            if current_pref is None and (name.endswith('éƒ½') or name.endswith('é“') or name.endswith('åºœ') or name.endswith('çœŒ')):
                 current_pref = name
                 continue

            if current_pref is None:
                continue

            city_code = city_map.get((current_pref, name))
            if not city_code:
                 city_normalized = name.replace('ãƒ¶', 'ã‚±')
                 city_code = city_map.get((current_pref, city_normalized))
            
            if not city_code:
                # ãƒ­ã‚°ã‚’å‡ºã—ã¦ç¢ºèªã—ãŸã„ãŒã€å¤§é‡ã«å‡ºã‚‹ã®ã§æŽ§ãˆã‚‹ã‹ã€ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ãƒˆã«å«ã‚ã‚‹
                # print(f"  Mapping failed: {current_pref} {name}")
                continue
                
            # OS Type -> Unknown
            os_type = 'Unknown'
            
            # Student per PC
            # Computers per Student
            computer_per_student = None
            if 'pc_per_student' in col_indices:
                # æ—¢å­˜ã®ã‚«ãƒ©ãƒ (ç«¯æœ«/ç”Ÿå¾’)ãŒã‚ã‚‹å ´åˆ
                val = row[col_indices['pc_per_student']]
                try:
                    computer_per_student = float(str(val).replace(',', ''))
                except:
                    pass
            
            if computer_per_student is None and 'students' in col_indices and 'learner_pcs' in col_indices:
                 try:
                     s_val = float(str(row[col_indices['students']]).replace(',', ''))
                     p_val = float(str(row[col_indices['learner_pcs']]).replace(',', ''))
                     if s_val > 0 and p_val > 0:
                         # ä¿®æ­£: PCå°æ•° / ç”Ÿå¾’æ•° (1äººã‚ãŸã‚Šã®ç«¯æœ«æ•°)
                         computer_per_student = p_val / s_val
                 except:
                     pass

            try:
                self.cur.execute("""
                    INSERT INTO education_info (city_code, terminal_os_type, computer_per_student, survey_year, updated_at)
                    VALUES (%s, %s, %s, 2023, NOW())
                    ON CONFLICT (city_code) DO UPDATE SET
                        terminal_os_type = EXCLUDED.terminal_os_type,
                        computer_per_student = EXCLUDED.computer_per_student,
                        updated_at = NOW();
                """, (city_code, os_type, computer_per_student))
                success_count += 1
            except Exception as e:
                print(f"âŒ DB Error for {city}: {e}")
                self.conn.rollback()
        
        self.conn.commit()
        print(f"  -> Imported {success_count} records")
        return success_count

    def inspect_data(self, df):
        """ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ç¢ºèª"""
        if df is None:
            return

        print("\nðŸ“Š Data Inspection:")
        print(f"Rows: {len(df)}")
        print(f"Columns: {len(df.columns)}")
        
        # çœç•¥ã›ãšã«è¡¨ç¤º
        pd.set_option('display.max_rows', None)
        pd.set_option('display.max_columns', None)
        pd.set_option('display.width', 1000)

        print("\n--- First 30 rows (Raw) ---")
        print(df.head(30).to_string())
        
        print("-" * 60)

    def get_city_code_map(self):
        """è‡ªæ²»ä½“åã‹ã‚‰city_codeã¸ã®ãƒžãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ"""
        self.cur.execute("SELECT city_code, prefecture, city_name FROM municipalities")
        results = self.cur.fetchall()
        
        # (éƒ½é“åºœçœŒ, å¸‚åŒºç”ºæ‘) -> city_code
        mapping = {}
        for r in results:
            key = (r['prefecture'], r['city_name'])
            mapping[key] = r['city_code']
        return mapping

    def determine_os_type(self, row, cols):
        """OSã”ã¨ã®å°æ•°ã‹ã‚‰ä¸»è¦OSã‚’åˆ¤å®š"""
        os_counts = {
            'Chromebook': row.get(cols.get('Chrome OSç«¯æœ«', -1), 0),
            'Windows': row.get(cols.get('Windowsç«¯æœ«', -1), 0),
            'iOS': row.get(cols.get('iPadOSç«¯æœ«', -1), 0),
            'macOS': row.get(cols.get('macOSç«¯æœ«', -1), 0),
            'Android': row.get(cols.get('Androidç«¯æœ«', -1), 0),
        }
        
        # æ•°å€¤ã«å¤‰æ›ï¼ˆNaNã‚„æ–‡å­—åˆ—ã‚’é™¤åŽ»ï¼‰
        valid_counts = {}
        total = 0
        for os_name, val in os_counts.items():
            try:
                # æ•´å‚™æ¸ˆã¿ç«¯æœ«ã®ã†ã¡ã®å°æ•°ãªã®ã§ã€ã“ã“ã«ã¯æ•°å€¤ãŒå…¥ã‚‹ã¯ãš
                # ãŸã ã—'***'ã‚„'-'ãŒå…¥ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹
                if isinstance(val, (int, float)) and not pd.isna(val):
                   count = int(val)
                elif isinstance(val, str) and val.isnumeric():
                   count = int(val)
                else:
                   count = 0
                
                valid_counts[os_name] = count
                total += count
            except:
                pass
        
        if total == 0:
            return None

        # æœ€å¤§ã®OSã‚’æŽ¢ã™
        sorted_os = sorted(valid_counts.items(), key=lambda x: x[1], reverse=True)
        top_os, top_count = sorted_os[0]
        
        # 70%ä»¥ä¸Šãªã‚‰ãã®OSå˜ç‹¬ã€ãã†ã§ãªã‘ã‚Œã°Mix
        if top_count / total >= 0.7:
            return top_os
        else:
            return 'Mixed'

    def close(self):
        self.cur.close()
        self.conn.close()
        self.client.close()

if __name__ == "__main__":
    downloader = GigaDataDownloader()
    try:
        downloader.download_and_import_all()
    finally:
        downloader.close()
