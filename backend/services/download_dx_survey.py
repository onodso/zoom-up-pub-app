"""
DX Survey Data Downloader
ãƒ‡ã‚¸ã‚¿ãƒ«åºã€Œè‡ªæ²»ä½“DXã®å–çµ„ã«é–¢ã™ã‚‹ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã€ã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ãƒ»ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

Data Source:
https://www.digital.go.jp/resources/govdashboard/local-government-dx
"""

import httpx
import pandas as pd
import os
import psycopg2
from psycopg2.extras import RealDictCursor
from psycopg2.extras import Json
import io
import zipfile
import json
from datetime import datetime

class DXSurveyDownloader:
    # ãƒ‡ã‚¸ã‚¿ãƒ«åº è‡ªæ²»ä½“DXãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
    # 2024å¹´7æœˆ12æ—¥æ›´æ–°ç‰ˆ
    DATA_URL = "https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/51a5a201-e0dd-493f-9c21-0692402d93e6/85162d87/20240712_resources_govdashboard_local_governmentdx_table_01.zip"

    def __init__(self):
        self.client = httpx.Client(timeout=120.0, follow_redirects=True)
        self.conn = psycopg2.connect(
            host=os.getenv("POSTGRES_HOST", "localhost"),
            port=int(os.getenv("POSTGRES_PORT", "5432")),
            user=os.getenv("POSTGRES_USER", "zoom_admin"),
            password=os.getenv("POSTGRES_PASSWORD", "password"),
            dbname=os.getenv("POSTGRES_DB", "zoom_dx_db")
        )
        self.cur = self.conn.cursor(cursor_factory=RealDictCursor)

    def download_and_extract(self):
        """ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä¸­ã®CSV/Excelã‚’èª­ã¿è¾¼ã‚€"""
        print(f"Downloading data from: {self.DATA_URL}")
        try:
            response = self.client.get(self.DATA_URL)
            response.raise_for_status()
            print(f"âœ… Downloaded {len(response.content):,} bytes")

            with zipfile.ZipFile(io.BytesIO(response.content)) as z:
                print(f"Archive contains: {z.namelist()}")
                
                # æ‹¡å¼µå­ãŒ.csvã¾ãŸã¯.xlsxã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
                target_file = None
                for filename in z.namelist():
                    if filename.endswith('.csv') or filename.endswith('.xlsx'):
                        target_file = filename
                        break
                
                if not target_file:
                    print("âŒ No CSV or Excel file found in archive")
                    return None

                print(f"Processing file: {target_file}")
                
                with z.open(target_file) as f:
                    if target_file.endswith('.csv'):
                        # Shift-JIS or UTF-8 check might be needed
                        # ãƒ‡ã‚¸ã‚¿ãƒ«åºãƒ‡ãƒ¼ã‚¿ã¯Shift-JISã®å¯èƒ½æ€§ãŒé«˜ã„ãŒã€pd.read_csvã§è‡ªå‹•æ¤œçŸ¥ã‚’è©¦ã¿ã‚‹
                        try:
                            df = pd.read_csv(f, encoding='shift_jis')
                        except UnicodeDecodeError:
                            f.seek(0)
                            df = pd.read_csv(f, encoding='utf-8')
                    else:
                        df = pd.read_excel(f)
                    
                    return df

        except Exception as e:
            print(f"âŒ Error downloading/extracting data: {e}")
            import traceback
            traceback.print_exc()
            return None

    def inspect_data(self, df):
        """ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚’ç¢ºèªã—ã¦è¡¨ç¤ºã™ã‚‹"""
        if df is None:
            return

        print("\nğŸ“Š Data Inspection:")
        print(f"Rows: {len(df)}")
        print(f"Columns: {len(df.columns)}")
        print("\nColumn Names:")
        for i, col in enumerate(df.columns):
            print(f"{i}: {col}")
        
        print("\nFirst 3 rows:")
        print(df.head(3))

    def import_data(self, df):
        """ãƒ‡ãƒ¼ã‚¿ã‚’municipalitiesãƒ†ãƒ¼ãƒ–ãƒ«ã®dx_statusã‚«ãƒ©ãƒ ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        if df is None:
            return

        print("\nğŸš€ Starting Data Import...")
        print("Transforming data structure (Pivot)...")
        
        # 1. é …ç›®åï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ï¼‰ã‚’ä½œæˆ
        # Unnamed: 0 (ã‚«ãƒ†ã‚´ãƒªãƒ¼) ã¨ Unnamed: 1 (é …ç›®å) ã‚’çµåˆ
        headers = []
        for idx, row in df.iterrows():
            category = str(row.iloc[0]).replace('\n', '') if pd.notna(row.iloc[0]) else ""
            item = str(row.iloc[1]).replace('\n', '') if pd.notna(row.iloc[1]) else ""
            # ã‚«ãƒ†ã‚´ãƒªãŒç©ºã®å ´åˆã¯å‰è¡Œã®å€¤ã‚’åŸ‹ã‚ã‚‹å‡¦ç†ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œãªã„ãŒã€
            # ç¾çŠ¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã‚‹ã¨å…¨ã¦ã®è¡Œã«å…¥ã£ã¦ã„ã‚‹ã‹ã€ã‚ã‚‹ã„ã¯ã‚«ãƒ†ã‚´ãƒªã ã‘ç‹¬ç«‹ã—ãŸè¡Œã§ã¯ãªã„ã‚ˆã†ã ã£ãŸã€‚
            # ã‚·ãƒ³ãƒ—ãƒ«ã«çµåˆã™ã‚‹
            if category == item:
                headers.append(item)
            else:
                headers.append(f"{category}_{item}")

        # 2. è»¢ç½®å‡¦ç†
        # ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ï¼š3åˆ—ç›®ä»¥é™ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹2ä»¥é™ï¼‰
        # è¡Œï¼šé …ç›®ã€åˆ—ï¼šè‡ªæ²»ä½“
        # ã“ã‚Œã‚’ -> è¡Œï¼šè‡ªæ²»ä½“ã€åˆ—ï¼šé …ç›® ã«è»¢ç½®
        
        try:
            # ãƒ‡ãƒ¼ã‚¿ã®DataFrameï¼ˆè‡ªæ²»ä½“åˆ—ã®ã¿ï¼‰
            data_df = df.iloc[:, 2:]
            
            # è»¢ç½®
            df_T = data_df.T
            
            # ã‚«ãƒ©ãƒ åã‚’è¨­å®š
            # headersã®é•·ã•ã¨df_Tã®åˆ—æ•°ãŒä¸€è‡´ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
            if len(headers) != len(df_T.columns):
                print(f"âš ï¸ Header mismatch: Headers={len(headers)}, DataCols={len(df_T.columns)}")
                # å¼·å¼•ã«åˆã‚ã›ã‚‹ã‹ã‚¨ãƒ©ãƒ¼ã«ã™ã‚‹ã‹ã€‚ä¸€æ—¦ã‚¹ãƒ©ã‚¤ã‚¹ã§åˆã‚ã›ã‚‹
                df_T.columns = headers[:len(df_T.columns)]
            else:
                df_T.columns = headers
            
            print(f"Transformed DataFrame: {len(df_T)} municipalities x {len(df_T.columns)} items")
            
        except Exception as e:
            print(f"âŒ Error during data transformation: {e}")
            import traceback
            traceback.print_exc()
            return

        success_count = 0
        skip_count = 0
        
        # 3. ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ
        for city_name, row in df_T.iterrows():
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒè‡ªæ²»ä½“åã«ãªã£ã¦ã„ã‚‹
            if pd.isna(city_name) or str(city_name).startswith('Unnamed'):
                continue
            
            try:
                # ãƒ‡ãƒ¼ã‚¿ã®NaNã‚’Noneã«å¤‰æ›
                dx_data = row.where(pd.notnull(row), None).to_dict()
                
                # DBæ›´æ–°
                # è‡ªæ²»ä½“åã®æ­£è¦åŒ–ï¼ˆã‚¹ãƒšãƒ¼ã‚¹å‰Šé™¤ï¼‰
                city_name_str = str(city_name)
                city_name_normalized = city_name_str.replace(' ', '').replace('ã€€', '')
                
                self.cur.execute("""
                    UPDATE municipalities 
                    SET dx_status = %s, updated_at = NOW()
                    WHERE REPLACE(REPLACE(city_name, ' ', ''), 'ã€€', '') = %s
                    RETURNING city_code;
                """, (Json(dx_data), city_name_normalized))
                
                if self.cur.fetchone():
                    success_count += 1
                else:
                    # DBã«å­˜åœ¨ã—ãªã„è‡ªæ²»ä½“ï¼ˆåˆä½µå‰ã‚„åç§°ä¸ä¸€è‡´ãªã©ï¼‰
                    # print(f"Skipped (not found): {city_name_normalized}")
                    skip_count += 1
                    
            except Exception as e:
                print(f"Error importing {city_name}: {e}")
                self.conn.rollback()
                skip_count += 1
            
            # é€²æ—è¡¨ç¤º
            if (success_count + skip_count) % 100 == 0:
                self.conn.commit()
                print(f"Processed {success_count + skip_count} / {len(df_T)} municipalities... (Success: {success_count})")

        self.conn.commit()
        print(f"\nâœ… Import Completed!")
        print(f"Updated: {success_count}")
        print(f"Skipped: {skip_count}")

    def close(self):
        self.cur.close()
        self.conn.close()
        self.client.close()

if __name__ == "__main__":
    downloader = DXSurveyDownloader()
    try:
        df = downloader.download_and_extract()
        if df is not None:
            # downloader.inspect_data(df)
            
            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ
            downloader.import_data(df)
            
            # çµæœç¢ºèª
            downloader.cur.execute("SELECT COUNT(dx_status) FROM municipalities;")
            res = downloader.cur.fetchone()
            count = res['count'] if res else 0
            print(f"\nğŸ“Š Total municipalities with DX data: {count}")
            
    finally:
        downloader.close()
