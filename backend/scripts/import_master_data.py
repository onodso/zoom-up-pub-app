import sys
import os
from pathlib import Path
import pandas as pd
import psycopg2
from psycopg2.extras import execute_values

# Add backend to path to import config
sys.path.append(str(Path(__file__).parent.parent.parent))
from backend.config import settings

def main():
    csv_path = Path("data/localgov_master_integrated.csv")
    if not csv_path.exists():
        print(f"âŒ File not found: {csv_path}")
        return

    print(f"ğŸ”„ Reading {csv_path}...")
    df = pd.read_csv(csv_path)
    
    # Validation
    # Updated to match integrated CSV headers: lgcode, pref, city, lat, lng
    required_cols = ['lgcode', 'pref', 'city', 'lat', 'lng']
    for col in required_cols:
        if col not in df.columns:
            print(f"âŒ Missing column: {col}")
            return

    print(f"ğŸ”Œ Connecting to DB {settings.DB_HOST}...")
    try:
        conn = psycopg2.connect(
            host=settings.DB_HOST,
            port=settings.DB_PORT,
            database=settings.DB_NAME,
            user=settings.DB_USER,
            password=settings.DB_PASSWORD
        )
        cur = conn.cursor()
        
        # Upsert Method
        insert_query = """
            INSERT INTO municipalities 
            (city_code, prefecture, city_name, region, city_type, latitude, longitude, official_url)
            VALUES %s
            ON CONFLICT (city_code) DO UPDATE SET
                prefecture = EXCLUDED.prefecture,
                city_name = EXCLUDED.city_name,
                region = EXCLUDED.region,
                city_type = EXCLUDED.city_type,
                latitude = EXCLUDED.latitude,
                longitude = EXCLUDED.longitude,
                official_url = EXCLUDED.official_url,
                updated_at = NOW()
        """
        
        data_tuples = []
        for _, row in df.iterrows():
            official_url = row.get('url', None)
            city_name = row['city']
            
            # Simple city type detection if not present
            city_type = row.get('city_type') 
            # In integrated CSV, it might not exist, infer from name
            if pd.isna(city_type) or not city_type:
                if 'å¸‚' in city_name: city_type = 'å¸‚'
                elif 'åŒº' in city_name: city_type = 'åŒº'
                elif 'ç”º' in city_name: city_type = 'ç”º'
                elif 'æ‘' in city_name: city_type = 'æ‘'
            
            
            # Region Inference
            region_map = {
                "åŒ—æµ·é“": "åŒ—æµ·é“",
                "é’æ£®çœŒ": "æ±åŒ—", "å²©æ‰‹çœŒ": "æ±åŒ—", "å®®åŸçœŒ": "æ±åŒ—", "ç§‹ç”°çœŒ": "æ±åŒ—", "å±±å½¢çœŒ": "æ±åŒ—", "ç¦å³¶çœŒ": "æ±åŒ—",
                "èŒ¨åŸçœŒ": "é–¢æ±", "æ ƒæœ¨çœŒ": "é–¢æ±", "ç¾¤é¦¬çœŒ": "é–¢æ±", "åŸ¼ç‰çœŒ": "é–¢æ±", "åƒè‘‰çœŒ": "é–¢æ±", "æ±äº¬éƒ½": "é–¢æ±", "ç¥å¥ˆå·çœŒ": "é–¢æ±",
                "æ–°æ½ŸçœŒ": "ä¸­éƒ¨", "å¯Œå±±çœŒ": "ä¸­éƒ¨", "çŸ³å·çœŒ": "ä¸­éƒ¨", "ç¦äº•çœŒ": "ä¸­éƒ¨", "å±±æ¢¨çœŒ": "ä¸­éƒ¨", "é•·é‡çœŒ": "ä¸­éƒ¨", "å²é˜œçœŒ": "ä¸­éƒ¨", "é™å²¡çœŒ": "ä¸­éƒ¨", "æ„›çŸ¥çœŒ": "ä¸­éƒ¨",
                "ä¸‰é‡çœŒ": "è¿‘ç•¿", "æ»‹è³€çœŒ": "è¿‘ç•¿", "äº¬éƒ½åºœ": "è¿‘ç•¿", "å¤§é˜ªåºœ": "è¿‘ç•¿", "å…µåº«çœŒ": "è¿‘ç•¿", "å¥ˆè‰¯çœŒ": "è¿‘ç•¿", "å’Œæ­Œå±±çœŒ": "è¿‘ç•¿",
                "é³¥å–çœŒ": "ä¸­å›½", "å³¶æ ¹çœŒ": "ä¸­å›½", "å²¡å±±çœŒ": "ä¸­å›½", "åºƒå³¶çœŒ": "ä¸­å›½", "å±±å£çœŒ": "ä¸­å›½",
                "å¾³å³¶çœŒ": "å››å›½", "é¦™å·çœŒ": "å››å›½", "æ„›åª›çœŒ": "å››å›½", "é«˜çŸ¥çœŒ": "å››å›½",
                "ç¦å²¡çœŒ": "ä¹å·", "ä½è³€çœŒ": "ä¹å·", "é•·å´çœŒ": "ä¹å·", "ç†Šæœ¬çœŒ": "ä¹å·", "å¤§åˆ†çœŒ": "ä¹å·", "å®®å´çœŒ": "ä¹å·", "é¹¿å…å³¶çœŒ": "ä¹å·", "æ²–ç¸„çœŒ": "æ²–ç¸„"
            }
            region = region_map.get(row['pref'], "ãã®ä»–")

            data_tuples.append((
                str(row['lgcode']).zfill(6), # lgcode to city_code
                row['pref'],      # pref to prefecture
                city_name,        # city to city_name
                region,
                city_type,
                row['lat'],
                row['lng'],
                official_url
            ))
            
        execute_values(cur, insert_query, data_tuples)
        conn.commit()
        print(f"âœ… Successfully imported {len(data_tuples)} municipalities.")
        
    except Exception as e:
        print(f"âŒ DB Error: {e}")
    finally:
        if 'conn' in locals() and conn:
            conn.close()

if __name__ == "__main__":
    main()
